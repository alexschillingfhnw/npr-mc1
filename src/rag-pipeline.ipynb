{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how to use the RAG pipeline to generate answers for the questions defined in the cleantech evaluation dataset. The pipeline consists of the following steps:\n",
    "1. Data Preparation and Ingestion\n",
    "2. Embedding\n",
    "3. Store Embeddings in Vector Database\n",
    "4. Retrieve Contexts\n",
    "5. Generate Prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import AzureOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import credentials\n",
    "\n",
    "deployment_name = \"gpt-4\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Ingestion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load and prepare the data, create embeddings for each chunk, and store the embeddings in a vector database. Since the data is already cleaned, we'll move directly to chunking and embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qatar to Slash Emissions as LNG Expansion Adva...</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>Qatar Petroleum (QP) is targeting aggressive c...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India Launches Its First 700 MW PHWR</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>Nuclear Power Corp of India Ltd (NPCIL) synchr...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Chapter for US-China Energy Trade</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>New US President Joe Biden took office this we...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japan: Slow Restarts Cast Doubt on 2030 Energy...</td>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>The slow pace of Japanese reactor restarts con...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYC Pension Funds to Divest Fossil Fuel Shares</td>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>Two of New York City's largest pension funds s...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        date  \\\n",
       "0  Qatar to Slash Emissions as LNG Expansion Adva...  2021-01-13   \n",
       "1               India Launches Its First 700 MW PHWR  2021-01-15   \n",
       "2              New Chapter for US-China Energy Trade  2021-01-20   \n",
       "3  Japan: Slow Restarts Cast Doubt on 2030 Energy...  2021-01-22   \n",
       "4     NYC Pension Funds to Divest Fossil Fuel Shares  2021-01-25   \n",
       "\n",
       "                                             content       domain  \\\n",
       "0  Qatar Petroleum (QP) is targeting aggressive c...  energyintel   \n",
       "1  Nuclear Power Corp of India Ltd (NPCIL) synchr...  energyintel   \n",
       "2  New US President Joe Biden took office this we...  energyintel   \n",
       "3  The slow pace of Japanese reactor restarts con...  energyintel   \n",
       "4  Two of New York City's largest pension funds s...  energyintel   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
       "1  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
       "2  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
       "3  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
       "4  https://www.energyintel.com/0000017b-a7dc-de4c...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/processed/cleantech_processed.csv')\n",
    "data_eval = pd.read_csv('../data/evaluation/cleantech_rag_evaluation_data_2024-09-20.csv', delimiter=\";\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles in the dataset:  9593\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of articles in the dataset: \", len(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `chunk_size`: Sets the maximum character length of each chunk to 1000 characters.\n",
    "- `chunk_overlap`: Adds a n-character overlap between chunks to preserve context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>content_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qatar to Slash Emissions as LNG Expansion Adva...</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>Qatar Petroleum (QP) is targeting aggressive c...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "      <td>Qatar Petroleum (QP) is targeting aggressive c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qatar to Slash Emissions as LNG Expansion Adva...</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>Qatar Petroleum (QP) is targeting aggressive c...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "      <td>million tons/yr. Qatar currently has an LNG pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qatar to Slash Emissions as LNG Expansion Adva...</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>Qatar Petroleum (QP) is targeting aggressive c...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "      <td>be too expensive and none met its targeted 50 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India Launches Its First 700 MW PHWR</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>Nuclear Power Corp of India Ltd (NPCIL) synchr...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "      <td>Nuclear Power Corp of India Ltd (NPCIL) synchr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India Launches Its First 700 MW PHWR</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>Nuclear Power Corp of India Ltd (NPCIL) synchr...</td>\n",
       "      <td>energyintel</td>\n",
       "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
       "      <td>will likely not be met. India's nuclear suppli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        date  \\\n",
       "0  Qatar to Slash Emissions as LNG Expansion Adva...  2021-01-13   \n",
       "1  Qatar to Slash Emissions as LNG Expansion Adva...  2021-01-13   \n",
       "2  Qatar to Slash Emissions as LNG Expansion Adva...  2021-01-13   \n",
       "3               India Launches Its First 700 MW PHWR  2021-01-15   \n",
       "4               India Launches Its First 700 MW PHWR  2021-01-15   \n",
       "\n",
       "                                             content       domain  \\\n",
       "0  Qatar Petroleum (QP) is targeting aggressive c...  energyintel   \n",
       "1  Qatar Petroleum (QP) is targeting aggressive c...  energyintel   \n",
       "2  Qatar Petroleum (QP) is targeting aggressive c...  energyintel   \n",
       "3  Nuclear Power Corp of India Ltd (NPCIL) synchr...  energyintel   \n",
       "4  Nuclear Power Corp of India Ltd (NPCIL) synchr...  energyintel   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.energyintel.com/0000017b-a7dc-de4c...   \n",
       "1  https://www.energyintel.com/0000017b-a7dc-de4c...   \n",
       "2  https://www.energyintel.com/0000017b-a7dc-de4c...   \n",
       "3  https://www.energyintel.com/0000017b-a7dc-de4c...   \n",
       "4  https://www.energyintel.com/0000017b-a7dc-de4c...   \n",
       "\n",
       "                                      content_chunks  \n",
       "0  Qatar Petroleum (QP) is targeting aggressive c...  \n",
       "1  million tons/yr. Qatar currently has an LNG pr...  \n",
       "2  be too expensive and none met its targeted 50 ...  \n",
       "3  Nuclear Power Corp of India Ltd (NPCIL) synchr...  \n",
       "4  will likely not be met. India's nuclear suppli...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define a function to perform chunking with adjustable parameters\n",
    "def chunk_text(dataframe, text_column, chunk_size=1000, chunk_overlap=100):\n",
    "    # Initialize RecursiveCharacterTextSplitter with dynamic parameters\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    # Split text in the specified column\n",
    "    dataframe['content_chunks'] = dataframe[text_column].apply(lambda text: text_splitter.split_text(text))\n",
    "    \n",
    "    # Flatten the DataFrame for individual chunk rows\n",
    "    chunked_df = dataframe.explode('content_chunks').reset_index(drop=True)\n",
    "\n",
    "    return chunked_df\n",
    "\n",
    "# Apply the chunking with adjustable parameters\n",
    "chunked_data = chunk_text(data, text_column='content', chunk_size=1000, chunk_overlap=100)\n",
    "chunked_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48039"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have chunked the texts into smaller segments, the next step is to pass these chunks through an embedding model to obtain their vector representations. The embedding model maps the textual information into high-dimensional vector spaces, where semantic similarities and relationships are preserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text, model): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "chunked_data['embeddings'] = chunked_data[\"content_chunks\"].apply(lambda x: generate_embeddings(x, \"text-embedding-3-large\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the embeddings:  3072\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of the embeddings: \", len(chunked_data['embeddings'][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `chunked_data` DataFrame is structured so that each row represents an individual **chunk** of text derived from the original documents, with a corresponding **embedding vector** stored in the `embeddings` column. Each embedding vector is a dense list of floating-point numbers (3072 dimensions in our case, given the use of the `text-embedding-3-large` model) that encapsulates the semantic meaning of the text chunk.\n",
    "\n",
    "These embeddings are critical for the RAG system, as they allow efficient similarity searches and retrieval tasks by representing the content of each text chunk in a high-dimensional vector space. When a query is embedded, the RAG system can quickly locate the most relevant text chunks by identifying embedding vectors in the database that are closest in meaning. This approach enables the system to retrieve contextually relevant information by comparing semantic relationships, streamlining the entire retrieval process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Embeddings in a Vector Database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone is a hosted vector database. We will store the embeddings in Pinecone."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize Pinecone Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, Index, ServerlessSpec\n",
    "\n",
    "# Initialize Pinecone with the new class-based approach\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "\n",
    "existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "\n",
    "# Define the index name and check if it exists\n",
    "index_name = \"npr-mc1\"\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,  # Dimension should match embedding model's output dimension\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "pinecone_index = pc.Index(index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store Embeddings in Pinecone**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When upserting larger amounts of data, it is recommended to upsert records in large batches. A batch of upserts should be as large as possible (up to 1000 records) without exceeding the maximum request size of 2MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 56}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "for idx, row in chunked_data.iterrows():\n",
    "    doc_id = str(row['index'] if 'index' in chunked_data.columns else idx)\n",
    "    embedding = row['embeddings']\n",
    "    original_text = row['content_chunks']\n",
    "\n",
    "    records.append({\n",
    "        \"id\": doc_id,\n",
    "        \"values\": embedding,\n",
    "        \"metadata\": {\"text\": original_text}\n",
    "    })\n",
    "\n",
    "# Upsert all records at once\n",
    "pinecone_index.upsert(vectors=records)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Processing (Retriever Module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a retrieval function that uses Pinecone for fetching relevant chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query, top_k=5):\n",
    "    query_embedding = generate_embeddings(query, \"text-embedding-3-large\")\n",
    "\n",
    "    # Retrieve similar documents from Pinecone\n",
    "    results = pinecone_index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_values=True,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant chunks for the following question:\n",
      "What did Qatar Petroleum mention what will happen in Phase 1 of the LNG expansion? \n",
      "\n",
      "Chunk ID: 0\n",
      "Qatar Petroleum (QP) is targeting aggressive cuts in its greenhouse gas emissions as it prepares to launch Phase 2 of its planned 48 million ton per year LNG expansion. In its latest Sustainability Report published on Wednesday, QP said its goals include reducing the emissions intensity of Qatar's L...\n",
      "Similarity Score: 0.72\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk ID: 1\n",
      "of Qatar's massive LNG expansion. But McDermott International said last week that it had been awarded the front end engineering and design contract for five offshore wellhead platforms (LNGI Jan12'21). Bids for construction of all four trains for Phase 1 of the LNG expansion were submitted in Septem...\n",
      "Similarity Score: 0.66\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk ID: 6\n",
      "could hinder CNOOCs ability to develop its domestic offshore resources, unless Biden reverses it. Last years Phase 1 trade deal entailed China spending an unrealistically high $ 185 billion above the 2017 baseline on US energy products, a goal made all the more impossible by Chinas demand plunge fro...\n",
      "Similarity Score: 0.33\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk ID: 7\n",
      "1 target. Shipping data suggest Chinas US crude imports at 407,000 b/d for January, down from 851,000 b/d in December, according to Kpler. They are going to wait and see the policy under the Biden administration, said Energy Aspects analyst Yuntao Liu. Shipping data suggest Chinas US crude imports a...\n",
      "Similarity Score: 0.31\n",
      "--------------------------------------------------------------------------------\n",
      "Chunk ID: 2\n",
      "Nuclear Power Corp of India Ltd (NPCIL) synchronized Kakrapar 3 in the western state of Gujarat to the grid on Jan 10, making it the first of India's 700 megawatt indigenously developed pressurized heavy water reactors (PHWRs) to reach this milestone (NIW Sep18'20). The news was tweeted by Anil Kako...\n",
      "Similarity Score: 0.31\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example question\n",
    "question = \"What did Qatar Petroleum mention what will happen in Phase 1 of the LNG expansion?\"\n",
    "\n",
    "# Call the retrieve_relevant_chunks function with the question\n",
    "relevant_chunks = retrieve_relevant_chunks(question, top_k=5)\n",
    "\n",
    "print(\"Most relevant chunks for the following question:\")\n",
    "print(question, \"\\n\")\n",
    "\n",
    "# Loop through each retrieved chunk and print its details\n",
    "for match in relevant_chunks.matches:\n",
    "    chunk_id = match.id\n",
    "    text_content = match.metadata.get('text', '')[:300]\n",
    "    score = match.score\n",
    "    \n",
    "    print(f\"Chunk ID: {chunk_id}\")\n",
    "    print(f\"{text_content}...\")\n",
    "    print(f\"Similarity Score: {score:.2f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Answers (Generator Module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now implement the Generator Module to generate answers based on the retrieved chunks using Azure OpenAI's GPT-4. In this step, we will create a function that takes a user query and the retrieved chunks, composes a relevant context from those chunks, and then uses GPT-4 to generate an answer based on this context."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model`: \n",
    "- `max_tokens`:\n",
    "- `temperature`:\n",
    "- `top_p`:\n",
    "- `top_k`:\n",
    "- `stop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, chunks):\n",
    "    # Compose the context from the retrieved chunks, handling potential missing metadata\n",
    "    context = \" \".join(chunk.get('metadata', {}).get('text', '') for chunk in chunks['matches'])\n",
    "    \n",
    "    # Generate the answer using Azure OpenAI GPT-4\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Please answer the query with the provided context.\"},\n",
    "            {\"role\": \"system\", \"content\": context},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        model = deployment_name,\n",
    "        max_tokens=250,\n",
    "        temperature=0.3,            # Adjust temperature for concise answers\n",
    "        stop=[\"End of answer\"],     # Optionally add a stop sequence\n",
    "    )\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer:\n",
      " Qatar Petroleum (QP) mentioned that about 22 million tons/yr of the carbon capture goal will come from the 32 million ton/yr Phase 1 of the LNG expansion, also known as the North Field East project. Bids for construction of all four trains for Phase 1 of the LNG expansion were submitted, but QP judged them to be too expensive and none met its targeted 50 week construction schedule. Contractors were asked to look for cost savings and submit new bids. The contract, estimated to be worth around $35 billion, is expected to be awarded by Mar 31. After the construction contract is awarded, QP is expected to select foreign investments partners to take stakes of up to 30% in the Phase 1 trains. Exxon Mobil, Royal Dutch Shell, Total, Chevron, ConocoPhillips and Eni have been shortlisted.\n"
     ]
    }
   ],
   "source": [
    "# Generate answer based on retrieved chunks\n",
    "generated_answer = generate_answer(question, relevant_chunks)\n",
    "\n",
    "print(\"Generated Answer:\\n\", generated_answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BLEU Score: Measures the overlap of n-grams between the generated answer and the reference answer. This metric is valuable for measuring content similarity, especially for factual information.\n",
    "- ROUGE Score: Commonly used for summarization tasks, it also evaluates the overlap of n-grams but considers recall more heavily, which is beneficial for checking if generated responses capture the core content.\n",
    "- Cosine Similarity: Measures the semantic similarity between the generated answer and the reference answer in embedding space. This ensures that even if the wording differs, the underlying meaning is still preserved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**:\n",
    "\n",
    "We have `data_eval`, which contains fields such as `question`, `relevant_text`, `answer`, and `article_url`. Each row represents an evaluation example, with the `question` to be queried in our pipeline, the `relevant_text` providing context for manual verification, and `answer` as the ground-truth answer to compare against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevant_text</th>\n",
       "      <th>answer</th>\n",
       "      <th>article_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the innovation behind Leclanché's new ...</td>\n",
       "      <td>Leclanché said it has developed an environment...</td>\n",
       "      <td>Leclanché's innovation is using a water-based ...</td>\n",
       "      <td>https://www.sgvoice.net/strategy/technology/23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the EU’s Green Deal Industrial Plan?</td>\n",
       "      <td>The Green Deal Industrial Plan is a bid by the...</td>\n",
       "      <td>The EU’s Green Deal Industrial Plan aims to en...</td>\n",
       "      <td>https://www.sgvoice.net/policy/25396/eu-seeks-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the EU’s Green Deal Industrial Plan?</td>\n",
       "      <td>The European counterpart to the US Inflation R...</td>\n",
       "      <td>The EU’s Green Deal Industrial Plan aims to en...</td>\n",
       "      <td>https://www.pv-magazine.com/2023/02/02/europea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>What are the four focus areas of the EU's Gree...</td>\n",
       "      <td>The new plan is fundamentally focused on four ...</td>\n",
       "      <td>The four focus areas of the EU's Green Deal In...</td>\n",
       "      <td>https://www.sgvoice.net/policy/25396/eu-seeks-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>When did the cooperation between GM and Honda ...</td>\n",
       "      <td>What caught our eye was a new hookup between G...</td>\n",
       "      <td>July 2013</td>\n",
       "      <td>https://cleantechnica.com/2023/05/08/general-m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_id  question_id                                           question  \\\n",
       "0           1            1  What is the innovation behind Leclanché's new ...   \n",
       "1           2            2       What is the EU’s Green Deal Industrial Plan?   \n",
       "2           3            2       What is the EU’s Green Deal Industrial Plan?   \n",
       "3           4            3  What are the four focus areas of the EU's Gree...   \n",
       "4           5            4  When did the cooperation between GM and Honda ...   \n",
       "\n",
       "                                       relevant_text  \\\n",
       "0  Leclanché said it has developed an environment...   \n",
       "1  The Green Deal Industrial Plan is a bid by the...   \n",
       "2  The European counterpart to the US Inflation R...   \n",
       "3  The new plan is fundamentally focused on four ...   \n",
       "4  What caught our eye was a new hookup between G...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Leclanché's innovation is using a water-based ...   \n",
       "1  The EU’s Green Deal Industrial Plan aims to en...   \n",
       "2  The EU’s Green Deal Industrial Plan aims to en...   \n",
       "3  The four focus areas of the EU's Green Deal In...   \n",
       "4                                          July 2013   \n",
       "\n",
       "                                         article_url  \n",
       "0  https://www.sgvoice.net/strategy/technology/23...  \n",
       "1  https://www.sgvoice.net/policy/25396/eu-seeks-...  \n",
       "2  https://www.pv-magazine.com/2023/02/02/europea...  \n",
       "3  https://www.sgvoice.net/policy/25396/eu-seeks-...  \n",
       "4  https://cleantechnica.com/2023/05/08/general-m...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPipeline:\n",
    "    def __init__(self, retriever, generator):\n",
    "        self.retriever = retriever\n",
    "        self.generator = generator\n",
    "\n",
    "    def retrieve_relevant_chunks(self, query, top_k=5):\n",
    "        return self.retriever(query, top_k=top_k)\n",
    "\n",
    "    def generate_answer(self, query, retrieved_chunks):\n",
    "        return self.generator(query, retrieved_chunks)\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = RAGPipeline(\n",
    "    retriever=retrieve_relevant_chunks,   # Your retrieval function\n",
    "    generator=generate_answer             # Your generation function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderschilling/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/alexanderschilling/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/alexanderschilling/anaconda3/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Evaluation Metrics:\n",
      " recall         0.043478\n",
      "bleu           0.029453\n",
      "rouge1         0.157721\n",
      "rouge2         0.087592\n",
      "rougeL         0.141349\n",
      "exact_match    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Function to calculate evaluation metrics for each example\n",
    "def evaluate_example(query, true_answer, pipeline):\n",
    "    # Retrieve relevant chunks\n",
    "    relevant_chunks = pipeline.retrieve_relevant_chunks(query)\n",
    "    \n",
    "    # Generate answer based on retrieved chunks\n",
    "    generated_answer = pipeline.generate_answer(query, relevant_chunks)\n",
    "    \n",
    "    # 1. Calculate Retrieval Recall\n",
    "    retrieved_texts = [chunk.metadata.get('text', '') for chunk in relevant_chunks['matches']]\n",
    "    recall = int(true_answer in \" \".join(retrieved_texts))\n",
    "\n",
    "    # 2. Calculate BLEU Score\n",
    "    bleu_score = sentence_bleu([true_answer.split()], generated_answer.split())\n",
    "    \n",
    "    # 3. Calculate ROUGE Scores\n",
    "    rouge_scores = scorer.score(true_answer, generated_answer)\n",
    "    rouge1 = rouge_scores['rouge1'].fmeasure\n",
    "    rouge2 = rouge_scores['rouge2'].fmeasure\n",
    "    rougeL = rouge_scores['rougeL'].fmeasure\n",
    "    \n",
    "    # 4. Exact Match (EM)\n",
    "    exact_match = int(generated_answer.strip() == true_answer.strip())\n",
    "    \n",
    "    return {\n",
    "        \"recall\": recall,\n",
    "        \"bleu\": bleu_score,\n",
    "        \"rouge1\": rouge1,\n",
    "        \"rouge2\": rouge2,\n",
    "        \"rougeL\": rougeL,\n",
    "        \"exact_match\": exact_match,\n",
    "        \"generated_answer\": generated_answer\n",
    "    }\n",
    "\n",
    "# Function to evaluate the entire dataset\n",
    "def evaluate_pipeline(data_eval, pipeline):\n",
    "    results = []\n",
    "    for _, row in data_eval.iterrows():\n",
    "        query = row['question']\n",
    "        true_answer = row['answer']\n",
    "        \n",
    "        # Evaluate this example\n",
    "        example_results = evaluate_example(query, true_answer, pipeline)\n",
    "        example_results['example_id'] = row['example_id']\n",
    "        results.append(example_results)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_pipeline(data_eval, pipeline)\n",
    "evaluation_results.head()\n",
    "\n",
    "# Display aggregated scores\n",
    "average_scores = evaluation_results[['recall', 'bleu', 'rouge1', 'rouge2', 'rougeL', 'exact_match']].mean()\n",
    "print(\"Average Evaluation Metrics:\\n\", average_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>example_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.992897e-155</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text does not contain information...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.071619e-02</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided context does not contain informat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.071619e-02</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided context does not contain informat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.255657e-01</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided context does not contain informat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not provide information on when ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text does not contain any informa...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1.669782e-01</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text does not contain information...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>6.559657e-156</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not provide information on what ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not provide information on wheth...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, you can hang solar panels on garden fence...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not provide information on who d...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>5.178101e-02</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided context does not contain informat...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1.120041e-231</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not provide information on the b...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>7.166071e-02</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0</td>\n",
       "      <td>Melting ice contributes to global warming due ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided context does not contain informat...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided context does not contain informat...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided text does not provide information...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1.132373e-231</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0</td>\n",
       "      <td>Agrivoltaics, also known as solar sharing, is ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3.288646e-155</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0</td>\n",
       "      <td>Agrivoltaics, also known as solar sharing or d...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided context does not contain informat...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>4.402213e-232</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not provide information on the o...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The text does not provide information on the t...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>3.826214e-155</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>The provided context does not contain informat...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recall           bleu    rouge1    rouge2    rougeL  exact_match  \\\n",
       "0        0  4.992897e-155  0.325581  0.195122  0.325581            0   \n",
       "1        0   3.071619e-02  0.285714  0.222222  0.250000            0   \n",
       "2        0   3.071619e-02  0.285714  0.222222  0.250000            0   \n",
       "3        0   3.255657e-01  0.565217  0.500000  0.521739            0   \n",
       "4        0   0.000000e+00  0.000000  0.000000  0.000000            0   \n",
       "5        0   0.000000e+00  0.000000  0.000000  0.000000            0   \n",
       "6        0   1.669782e-01  0.380952  0.300000  0.333333            0   \n",
       "7        0  6.559657e-156  0.196078  0.122449  0.156863            0   \n",
       "8        0   0.000000e+00  0.000000  0.000000  0.000000            0   \n",
       "9        0   0.000000e+00  0.020833  0.000000  0.020833            0   \n",
       "10       0   0.000000e+00  0.066667  0.000000  0.066667            0   \n",
       "11       0   5.178101e-02  0.290909  0.188679  0.254545            0   \n",
       "12       0  1.120041e-231  0.181818  0.000000  0.181818            0   \n",
       "13       0   7.166071e-02  0.338983  0.137931  0.322034            0   \n",
       "14       0   0.000000e+00  0.000000  0.000000  0.000000            0   \n",
       "15       1   0.000000e+00  0.000000  0.000000  0.000000            0   \n",
       "16       0   0.000000e+00  0.000000  0.000000  0.000000            0   \n",
       "17       0  1.132373e-231  0.232558  0.000000  0.162791            0   \n",
       "18       0  3.288646e-155  0.189655  0.035088  0.137931            0   \n",
       "19       0   0.000000e+00  0.062500  0.000000  0.062500            0   \n",
       "20       0  4.402213e-232  0.037736  0.000000  0.037736            0   \n",
       "21       0   0.000000e+00  0.000000  0.000000  0.000000            0   \n",
       "22       0  3.826214e-155  0.166667  0.090909  0.166667            0   \n",
       "\n",
       "                                     generated_answer  example_id  \n",
       "0   The provided text does not contain information...           1  \n",
       "1   The provided context does not contain informat...           2  \n",
       "2   The provided context does not contain informat...           3  \n",
       "3   The provided context does not contain informat...           4  \n",
       "4   The text does not provide information on when ...           5  \n",
       "5   The provided text does not contain any informa...           6  \n",
       "6   The provided text does not contain information...           7  \n",
       "7   The text does not provide information on what ...           8  \n",
       "8   The text does not provide information on wheth...           9  \n",
       "9   Yes, you can hang solar panels on garden fence...          10  \n",
       "10  The text does not provide information on who d...          11  \n",
       "11  The provided context does not contain informat...          12  \n",
       "12  The text does not provide information on the b...          13  \n",
       "13  Melting ice contributes to global warming due ...          14  \n",
       "14  The provided context does not contain informat...          15  \n",
       "15  The provided context does not contain informat...          16  \n",
       "16  The provided text does not provide information...          17  \n",
       "17  Agrivoltaics, also known as solar sharing, is ...          18  \n",
       "18  Agrivoltaics, also known as solar sharing or d...          19  \n",
       "19  The provided context does not contain informat...          20  \n",
       "20  The text does not provide information on the o...          21  \n",
       "21  The text does not provide information on the t...          22  \n",
       "22  The provided context does not contain informat...          23  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to test the RAG pipeline on evaluation data\n",
    "def test_pipeline_on_eval_data(data_eval, top_k=5):\n",
    "    results = []\n",
    "\n",
    "    for _, row in data_eval.iterrows():\n",
    "        question = row['question']\n",
    "        expected_answer = row['answer']\n",
    "        example_id = row['example_id']\n",
    "        \n",
    "        # Retrieve relevant chunks for each question\n",
    "        retrieved_chunks = retrieve_relevant_chunks(question, top_k=top_k)\n",
    "        \n",
    "        # Generate answer based on retrieved chunks\n",
    "        generated_answer = generate_answer(question, retrieved_chunks)\n",
    "        \n",
    "        # Store results for later analysis\n",
    "        results.append({\n",
    "            'example_id': example_id,\n",
    "            'question': question,\n",
    "            'expected_answer': expected_answer,\n",
    "            'generated_answer': generated_answer,\n",
    "            'retrieved_chunks': retrieved_chunks\n",
    "        })\n",
    "    \n",
    "    # Convert results to DataFrame for easier analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline on evaluation data\n",
    "results_df = test_pipeline_on_eval_data(data_eval)\n",
    "results_df[['example_id', 'question', 'expected_answer', 'generated_answer', 'retrieved_chunks']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd9c78cbb62892232a2e8cf9a4bd699d988202e949c50bb9be5232199c394801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
